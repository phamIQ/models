{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39488ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries:\n",
    "# pip install torch torchvision torchaudio scikit-learn numpy tensorboard\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "import copy\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8455e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Important: Update these paths !!\n",
    "DATA_DIR = \"path to data\"\n",
    "MODEL_SAVE_PATH = \"output here \"\n",
    "BEST_OVERALL_MODEL_FILENAME = \"tomato_best_model.pth\"\n",
    "TENSORBOARD_LOG_DIR = \"log files\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100406ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_device():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    return device\n",
    "\n",
    "def get_data_transforms():\n",
    "    return {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "\n",
    "def load_datasets(data_dir, data_transforms):\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "    class_names = None\n",
    "    test_dir = os.path.join(data_dir, 'test')\n",
    "    if not os.path.isdir(test_dir):\n",
    "        print(f\"Warning: Test directory not found at {test_dir}. Testing will be skipped.\")\n",
    "        splits = ['train', 'valid']\n",
    "    else:\n",
    "        splits = ['train', 'valid', 'test']\n",
    "\n",
    "    for x in splits:\n",
    "        try:\n",
    "            image_datasets[x] = datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "            shuffle = (x == 'train')\n",
    "            dataloaders[x] = DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=NUM_WORKERS)\n",
    "            dataset_sizes[x] = len(image_datasets[x])\n",
    "            print(f\"Loaded {dataset_sizes[x]} images for {x}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Dataset directory not found for split '{x}' at {os.path.join(data_dir, x)}\")\n",
    "            if x == 'train' or x == 'valid': raise\n",
    "            else:\n",
    "                 print(f\"Skipping {x} split.\")\n",
    "                 if x in splits: splits.remove(x)\n",
    "\n",
    "    if 'train' in image_datasets:\n",
    "        class_names = image_datasets['train'].classes\n",
    "        print(f\"Classes: {class_names}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Training data is required.\")\n",
    "\n",
    "    return image_datasets, dataloaders, dataset_sizes, class_names, splits\n",
    "\n",
    "def modify_model_classifier(model_name, model, num_classes):\n",
    "    for param in model.parameters(): param.requires_grad = False\n",
    "\n",
    "    if model_name == \"ResNet50\":\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(nn.Linear(in_features, 512), nn.ReLU(), nn.Dropout(0.5), nn.Linear(512, num_classes))\n",
    "        for param in model.fc.parameters(): param.requires_grad = True\n",
    "    elif model_name == \"AlexNet\":\n",
    "        in_features = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(in_features, num_classes)\n",
    "        for param in model.classifier[6].parameters(): param.requires_grad = True\n",
    "    elif model_name == \"MobileNet\":\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "        for param in model.classifier[1].parameters(): param.requires_grad = True\n",
    "    elif model_name == \"DenseNet\":\n",
    "        in_features = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(in_features, num_classes)\n",
    "        for param in model.classifier.parameters(): param.requires_grad = True\n",
    "    elif model_name == \"EfficientNet\":\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(nn.Dropout(p=0.4, inplace=True), nn.Linear(in_features, num_classes))\n",
    "        for param in model.classifier.parameters(): param.requires_grad = True\n",
    "    else:\n",
    "        print(f\"Warning: Classifier modification logic not defined for {model_name}.\")\n",
    "        if hasattr(model, 'fc'):\n",
    "            in_features = model.fc.in_features\n",
    "            model.fc = nn.Linear(in_features, num_classes)\n",
    "            for param in model.fc.parameters(): param.requires_grad = True\n",
    "        elif hasattr(model, 'classifier'):\n",
    "             if isinstance(model.classifier, nn.Sequential):\n",
    "                 try:\n",
    "                     last_layer = model.classifier[-1]\n",
    "                     if isinstance(last_layer, nn.Linear):\n",
    "                         in_features = last_layer.in_features\n",
    "                         model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "                         for param in model.classifier[-1].parameters(): param.requires_grad = True\n",
    "                     else: raise TypeError(\"Last classifier layer not Linear\")\n",
    "                 except Exception as e: print(f\"Could not auto-modify Sequential classifier for {model_name}: {e}\")\n",
    "             elif isinstance(model.classifier, nn.Linear):\n",
    "                 in_features = model.classifier.in_features\n",
    "                 model.classifier = nn.Linear(in_features, num_classes)\n",
    "                 for param in model.classifier.parameters(): param.requires_grad = True\n",
    "             else: print(f\"Unhandled classifier type {type(model.classifier)} for {model_name}\")\n",
    "        else: print(f\"Cannot find 'fc' or 'classifier' for {model_name}\")\n",
    "\n",
    "    print(f\"Modified {model_name} classifier for {num_classes} classes.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e90030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, model_name_str, criterion, optimizer, dataloaders, dataset_sizes, device, num_epochs, model_save_dir, writer):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    model_save_filename = os.path.join(model_save_dir, f\"{model_name_str}_best_val.pth\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train': model.train()\n",
    "            else: model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if writer:\n",
    "                writer.add_scalar(f'Loss/{phase}', epoch_loss, epoch)\n",
    "                writer.add_scalar(f'Accuracy/{phase}', epoch_acc, epoch)\n",
    "\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, model_save_filename)\n",
    "                print(f\"Saved new best model weights to {model_save_filename}\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc\n",
    "\n",
    "def test_model(model, dataloader, criterion, device, dataset_size):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    print(\"\\nEvaluating on Test Set...\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss = running_loss / dataset_size\n",
    "    test_acc = running_corrects.double() / dataset_size\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n",
    "    print(f'Test Precision (Macro): {precision:.4f}')\n",
    "    print(f'Test Recall (Macro): {recall:.4f}')\n",
    "    print(f'Test F1-Score (Macro): {f1:.4f}')\n",
    "\n",
    "    return test_loss, test_acc.item(), precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "device = setup_device()\n",
    "data_transforms = get_data_transforms()\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "os.makedirs(TENSORBOARD_LOG_DIR, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "image_datasets, dataloaders, dataset_sizes, class_names, available_splits = load_datasets(DATA_DIR, data_transforms)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Define models to train\n",
    "models_to_train = {\n",
    "    \"MobileNet\": lambda: models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1),\n",
    "}\n",
    "\n",
    "model_performance = {}\n",
    "best_overall_acc = 0.0\n",
    "best_overall_model_name = None\n",
    "best_overall_model_log_dir = None\n",
    "best_overall_model_weights_path = os.path.join(MODEL_SAVE_PATH, BEST_OVERALL_MODEL_FILENAME)\n",
    "\n",
    "# Training loop\n",
    "for model_name, model_loader in models_to_train.items():\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "    current_run_time = int(time.time())\n",
    "    log_dir = os.path.join(TENSORBOARD_LOG_DIR, f\"{model_name}_{current_run_time}\")\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    model = model_loader()\n",
    "    model = modify_model_classifier(model_name, model, num_classes)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    params_to_update = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(params_to_update, lr=LEARNING_RATE)\n",
    "\n",
    "    trained_model, best_val_acc = train_and_evaluate_model(\n",
    "        model, model_name, criterion, optimizer, dataloaders, dataset_sizes,\n",
    "        device, NUM_EPOCHS, MODEL_SAVE_PATH, writer\n",
    "    )\n",
    "\n",
    "    hparams = {\n",
    "        'model': model_name,\n",
    "        'lr': LEARNING_RATE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'optimizer': optimizer.__class__.__name__,\n",
    "        'epochs': NUM_EPOCHS\n",
    "    }\n",
    "    final_metrics = {\n",
    "        'hparam/best_val_accuracy': best_val_acc.item()\n",
    "    }\n",
    "    writer.add_hparams(hparams, final_metrics)\n",
    "    writer.close()\n",
    "\n",
    "    model_performance[model_name] = {\n",
    "        \"best_val_acc\": best_val_acc.item(),\n",
    "        \"log_dir\": log_dir\n",
    "    }\n",
    "\n",
    "    if best_val_acc > best_overall_acc:\n",
    "        best_overall_acc = best_val_acc\n",
    "        best_overall_model_name = model_name\n",
    "        best_overall_model_log_dir = log_dir\n",
    "        torch.save(trained_model.state_dict(), best_overall_model_weights_path)\n",
    "        print(f\"*** New best overall model: {model_name} (Val Acc: {best_overall_acc:.4f}). Saved to {best_overall_model_weights_path} ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeca68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training Summary ---\")\n",
    "sorted_performance = sorted(model_performance.items(), key=lambda item: item[1]['best_val_acc'], reverse=True)\n",
    "for model_name, metrics in sorted_performance:\n",
    "    print(f\"{model_name}: Best Validation Accuracy = {metrics['best_val_acc']:.4f} (Log Dir: {os.path.abspath(metrics['log_dir'])})\")\n",
    "\n",
    "if best_overall_model_name:\n",
    "    print(f\"\\nBest overall model (based on validation): {best_overall_model_name} with accuracy {best_overall_acc:.4f}\")\n",
    "\n",
    "    if 'test' in available_splits:\n",
    "        print(f\"\\n--- Testing the best model: {best_overall_model_name} ---\")\n",
    "        best_model_arch = models_to_train[best_overall_model_name]()\n",
    "        best_model_arch = modify_model_classifier(best_overall_model_name, best_model_arch, num_classes)\n",
    "        map_location = None if torch.cuda.is_available() else torch.device('cpu')\n",
    "        best_model_arch.load_state_dict(torch.load(best_overall_model_weights_path, map_location=map_location))\n",
    "        best_model_arch = best_model_arch.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        test_loss, test_acc, precision, recall, f1 = test_model(best_model_arch, dataloaders['test'], criterion, device, dataset_sizes['test'])\n",
    "\n",
    "        # Log test metrics to TensorBoard\n",
    "        test_writer = SummaryWriter(log_dir=best_overall_model_log_dir)\n",
    "        test_writer.add_scalar('Metrics/Test_Accuracy', test_acc, 0)\n",
    "        test_writer.add_scalar('Metrics/Test_Loss', test_loss, 0)\n",
    "        test_writer.add_scalar('Metrics/Test_Precision_Macro', precision, 0)\n",
    "        test_writer.add_scalar('Metrics/Test_Recall_Macro', recall, 0)\n",
    "        test_writer.add_scalar('Metrics/Test_F1_Macro', f1, 0)\n",
    "        test_writer.close()\n",
    "        print(f\"Logged test metrics to TensorBoard: {os.path.abspath(best_overall_model_log_dir)}\")\n",
    "    else:\n",
    "        print(\"\\nTest dataset not available or failed to load. Skipping final testing.\")\n",
    "else:\n",
    "    print(\"\\nNo models were trained successfully or no best model was identified.\")\n",
    "\n",
    "print(\"\\n\\n===================== TensorBoard Usage =====================\")\n",
    "\n",
    "print(f\"Log files were saved under the base directory:\")\n",
    "print(f\"  {os.path.abspath(TENSORBOARD_LOG_DIR)}\")\n",
    "\n",
    "print(f\"  tensorboard --logdir \\\"{os.path.abspath(TENSORBOARD_LOG_DIR)}\\\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0411e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
